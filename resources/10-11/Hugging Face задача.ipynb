{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Question-Answering System with Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, pipeline\n",
    "\n",
    "id = 'deepset/minilm-uncased-squad2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(id)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(id, from_pt=True)\n",
    "pipe = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What does NLP stand for?'\n",
    "\n",
    "context = 'Natural Language Processing, or NLP, encompasses a variety of \\\n",
    "           activities, including text classification, keyword and topic \\\n",
    "           extraction, text summarization, and language translation. The \\\n",
    "           accuracy of NLP models has improved in recent years for a variety \\\n",
    "           of reasons, not the least of which are newer and better ways of \\\n",
    "           converting words and sentences into dense vector representations \\\n",
    "           that incorporate context, and a relatively new neural-network \\\n",
    "           architecture called the transformer that can zero in on the most \\\n",
    "           meaningful words and even differentiate between multiple meanings \\\n",
    "           of the same word.'\n",
    "\n",
    "pipe(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'When was TensorFlow released?'\n",
    "\n",
    "context = 'Machine learning isn\\'t hard when you have a properly engineered \\\n",
    "           dataset to work with. The reason it\\'s not hard is libraries such as \\\n",
    "           Scikit-learn and ML.NET, which reduce complex learning algorithms to \\\n",
    "           a few lines of code. Deep learning isn’t difficult, either, thanks to \\\n",
    "           libraries such as the Microsoft Cognitive Toolkit (CNTK), Theano, \\\n",
    "           and PyTorch. But the library that most of the world has settled on \\\n",
    "           for building neural networks is TensorFlow, an open-source framework \\\n",
    "           created by Google that was released under the Apache License 2.0 in \\\n",
    "           2015.'\n",
    "\n",
    "pipe(question=question, context=context)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Is Keras part of TensorFlow?'\n",
    "\n",
    "context = 'The learning curve for TensorFlow is rather steep. Another library \\\n",
    "           named Keras provides a simplified Python interface to TensorFlow \\\n",
    "           and has emerged as the Scikit of deep learning. Keras is all about \\\n",
    "           neural networks. It began life as a stand-alone project in 2015 \\\n",
    "           but was integrated into TensorFlow in 2019. Any code that you write \\\n",
    "           using TensorFlow’s built-in Keras module ultimately executes in \\\n",
    "           (and is optimized for) TensorFlow. Even Google recommends using the \\\n",
    "           Keras API.'\n",
    "\n",
    "pipe(question=question, context=context)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Is it better to use Keras or TensorFlow to build neural networks?'\n",
    "pipe(question=question, context=context)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Data/passages.csv', header=None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "bert_id = 'sebastian-hofstaetter/distilbert-dot-margin_mse-T2-msmarco'\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_id) \n",
    "bert_model = TFAutoModel.from_pretrained(bert_id, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "    tokenized_text = bert_tokenizer(text, return_tensors='tf')\n",
    "    vectorized_text = bert_model(tokenized_text)[0][:, 0, :][0]\n",
    "    return vectorized_text\n",
    "\n",
    "contexts = data[0]\n",
    "vectorized_contexts = contexts.apply(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_best_contexts(query, contexts, max_matches=3):\n",
    "    scores = pd.Series(dtype='object')\n",
    "    tokenized_query = bert_tokenizer(query, return_tensors='tf')\n",
    "    vectorized_query = bert_model(tokenized_query)[0][:, 0, :][0]\n",
    "    \n",
    "    for idx, item in contexts.iteritems():\n",
    "        score = np.dot(vectorized_query, item)\n",
    "        scores = pd.concat([scores, pd.Series(score)], ignore_index=True)\n",
    "\n",
    "    sorted_scores = scores.sort_values(ascending=False)[:max_matches]\n",
    "    return list(sorted_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'How many versions of YOLO are there?'\n",
    "indexes = get_best_contexts(question, vectorized_contexts)\n",
    "\n",
    "for idx in indexes:\n",
    "    print(f'{contexts[idx]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in indexes:\n",
    "    output = pipe(question=question, context=contexts[idx], handle_impossible_answer=True)\n",
    "    \n",
    "    if output['start'] != output['end']:\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_answers(question, contexts, vectorized_contexts):\n",
    "    indexes = get_best_contexts(question, vectorized_contexts)\n",
    "    \n",
    "    for idx in indexes:\n",
    "        output = pipe(question=question, context=contexts[idx], handle_impossible_answer=True)\n",
    "\n",
    "        if output['start'] != output['end']:\n",
    "            print(f'{output[\"answer\"]} ({output[\"score\"]:.1%})')\n",
    "\n",
    "question = 'What type of neural network supports instance segmentation?'\n",
    "show_answers(question, contexts, vectorized_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What is YOLO\\'s primary weakness?'\n",
    "show_answers(question, contexts, vectorized_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Is TensorFlow difficult to learn?'\n",
    "show_answers(question, contexts, vectorized_contexts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
